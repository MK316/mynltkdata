{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Corpus_toolkit.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MK316/mynltkdata/blob/main/Corpus_toolkit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Corpus Toolkit: Source from Kristopher Kyle [[Github link]](\"https://github.com/kristopherkyle/corpus_toolkit\")\n",
        "\n",
        "https://github.com/kristopherkyle/corpus_toolkit"
      ],
      "metadata": {
        "id": "rDLFbCc458ns"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Module installation:"
      ],
      "metadata": {
        "id": "dHbOLQOE6iwI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Anraa9XB5xKW"
      },
      "outputs": [],
      "source": [
        "!pip install corpus-toolkit"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Note: \n",
        "### 1) We need data, brown_single.zip [download here](\"https://github.com/kristopherkyle/Corpus-Methods-Intro/blob/master/Course-Materials/brown_single.zip?raw=true\")\n",
        "### 2) The folder \"brown_single\" should be in your working directory: Below we clone github for the data.\n",
        "\n",
        "* Step 1. upload brown_single folder to your github\n",
        "\n",
        "* Step 2. clone github folder as follows\n"
      ],
      "metadata": {
        "id": "63_yzx-o6pY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/youraccountname/repositoryname/brown_single.git\n",
        "!git clone https://github.com/MK316/mynltkdata.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eg5Nda_79s-x",
        "outputId": "6ba0a240-d588-4e59-e0e4-a1cb23619b5a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mynltkdata'...\n",
            "remote: Enumerating objects: 506, done.\u001b[K\n",
            "remote: Counting objects: 100% (190/190), done.\u001b[K\n",
            "remote: Compressing objects: 100% (190/190), done.\u001b[K\n",
            "remote: Total 506 (delta 4), reused 182 (delta 0), pack-reused 316\u001b[K\n",
            "Receiving objects: 100% (506/506), 2.34 MiB | 17.11 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Note: Before changing working directory, check whether the folder (repository) is properly cloned on the left Files panel.\n",
        "\n",
        "* Step 3. Directory change: %cd /content/repositoryname/\n"
      ],
      "metadata": {
        "id": "eoi4hZ8tBYzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/mynltkdata/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jaU4Sqm-4Z8",
        "outputId": "86dc950b-bd79-42bb-af63-a360a8f54a99"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mynltkdata\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check current working directory: !pwd"
      ],
      "metadata": {
        "id": "RjrqTDNAB121"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__teVkXq_aKK",
        "outputId": "73b150e0-dac9-4388-91bd-e0b744cc34e9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mynltkdata\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is for further preprocessing when necessary\n",
        "!pip install -U spacy\n",
        "# python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "mSz2xa1i_Ybt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [1] Load, tokenize, and generate a frequency list\n",
        "Data: brown_single (500 files)"
      ],
      "metadata": {
        "id": "EzbO8FKEB8T1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from corpus_toolkit import corpus_tools as ct\n",
        "brown_corp = ct.ldcorpus(\"brown_single\") #load and read corpus\n",
        "tok_corp = ct.tokenize(brown_corp) #tokenize corpus - by default this lemmatizes as well\n",
        "brown_freq = ct.frequency(tok_corp) #creates a frequency dictionary"
      ],
      "metadata": {
        "id": "Sed7BTwb6h7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(brown_freq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FqSYUYrubi2",
        "outputId": "aafc4094-fc2e-4358-eac2-3ffcdcecc644"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35299"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "brown_freq['species']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMNkvnc0ufjo",
        "outputId": "3c5617ed-5b53-4c1d-a6f5-57f84e54e0a6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate concordance lines\n",
        "Concordance lines can be generated using the concord() function. By default, a random sample of 25 hits will be generated, with 10 tokens of left and right context."
      ],
      "metadata": {
        "id": "ymshK2xvDUfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conc_results1 = ct.concord(ct.tokenize(ct.ldcorpus(\"brown_single\"),lemma = False),[\"run\",\"ran\",\"running\",\"runs\"],nhits = 10)\n",
        "for x in conc_results1:\n",
        "\tprint(x)"
      ],
      "metadata": {
        "id": "Uyipi_Ku-cCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Added] Concordance with brown_single texts combined"
      ],
      "metadata": {
        "id": "tg7-6BEzvJVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQq8Kckuzye-",
        "outputId": "d37a34e4-2178-4761-c4be-cc6ac6f7bdfa"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# find all the txt files in the dataset folder\n",
        "inputs = []\n",
        "# url = \"/Users/mirankim/Desktop/data/brown_single/\"\n",
        "for file in os.listdir(\"brown_single\"):\n",
        "    if file.endswith(\".txt\"):\n",
        "        inputs.append(os.path.join(\"brown_single\", file))\n",
        " \n",
        " \n",
        "# concatanate all txt files in a file called merged_file.txt\n",
        "with open('merged_file.txt', 'w') as outfile:\n",
        "    for fname in inputs:\n",
        "        with open(fname, encoding=\"utf-8\", errors='ignore') as infile:\n",
        "            outfile.write(infile.read())"
      ],
      "metadata": {
        "id": "2ZNcLz9h6Zat"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the merged file\n",
        "file = open(\"merged_file.txt\",'r')\n",
        "text = file.read()\n",
        "file.close()"
      ],
      "metadata": {
        "id": "_tTKCC0d9Ymt"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "retokenize = RegexpTokenizer(\"[\\w]+\")\n",
        "words = retokenize.tokenize(text)"
      ],
      "metadata": {
        "id": "AMP1r1QtvI5Q"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find concordance example:"
      ],
      "metadata": {
        "id": "CGY8DhMpCZi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "item1 = input()\n",
        "nltk.Text(words).concordance(item1, 100, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvbCVzSlu1JD",
        "outputId": "cb48dc25-c901-4bbd-dd5a-a696ab3b7d43"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "merge\n",
            "Displaying 5 of 10 matches:\n",
            " human dignity Beyond the forest all our paths merge into a single great highway which ends in the \n",
            "edral And as the waves flow back and forth and merge with the waves from the neighboring atoms you \n",
            "o determine whether it would be appropriate to merge the responses for the purposes of the study Th\n",
            "hey can amuse each other until we get ready to merge sides All dressing undressing to be more exact\n",
            "mpetitive advantages to the lines that wish to merge However there is a more profound consideration\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The functions ldcorpus() and tokenize() are Python generators, which means that they must be re-declared each time they are used (iterated over). A slightly messier (but more appropriate) way to achieve the results above is to nest the commands."
      ],
      "metadata": {
        "id": "Vv1BGPiEDD_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#note that range can be calculated instead of frequency using the argument calc = \"range\"\n",
        "ct.head(brown_freq, hits = 20) #print top 10 items"
      ],
      "metadata": {
        "id": "Hda7TU7Q_Spn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brown_freq = ct.frequency(ct.tokenize(ct.ldcorpus(\"brown_single\")))\n",
        "ct.head(brown_freq, hits = 20)"
      ],
      "metadata": {
        "id": "CqWuAIl6HxQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collocation"
      ],
      "metadata": {
        "id": "3q3Kr9u5EID2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conc_results2 = ct.concord(ct.tokenize(ct.ldcorpus(\"brown_single\"),lemma = False),[\"run\",\"ran\",\"running\",\"runs\"],collocates = [\"quick\",\"quickly\"], nhits = 10)\n",
        "for x in conc_results2:\n",
        "\tprint(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pb_fi1TJEOBB",
        "outputId": "243dcc8f-bad2-484c-9299-392fab2bbb42"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing cb_cb27.txt (1 of 472 files)\n",
            "Processing ca_ca28.txt (2 of 472 files)\n",
            "Processing ck_ck26.txt (3 of 472 files)\n",
            "Processing cb_cb03.txt (4 of 472 files)\n",
            "Processing cn_cn27.txt (5 of 472 files)\n",
            "Processing cn_cn21.txt (6 of 472 files)\n",
            "Processing cg_cg39.txt (7 of 472 files)\n",
            "Processing cg_cg15.txt (8 of 472 files)\n",
            "Processing cg_cg68.txt (9 of 472 files)\n",
            "Processing ce_ce26.txt (10 of 472 files)\n",
            "Processing ck_ck27.txt (11 of 472 files)\n",
            "Processing cl_cl12.txt (12 of 472 files)\n",
            "Processing cb_cb11.txt (13 of 472 files)\n",
            "Processing cf_cf15.txt (14 of 472 files)\n",
            "Processing cf_cf35.txt (15 of 472 files)\n",
            "Processing ck_ck12.txt (16 of 472 files)\n",
            "Processing ck_ck10.txt (17 of 472 files)\n",
            "Processing cp_cp10.txt (18 of 472 files)\n",
            "Processing cc_cc02.txt (19 of 472 files)\n",
            "Processing cg_cg35.txt (20 of 472 files)\n",
            "Processing ck_ck16.txt (21 of 472 files)\n",
            "Processing ca_ca01.txt (22 of 472 files)\n",
            "Processing ch_ch26.txt (23 of 472 files)\n",
            "Processing cn_cn08.txt (24 of 472 files)\n",
            "Processing cl_cl22.txt (25 of 472 files)\n",
            "Processing ce_ce22.txt (26 of 472 files)\n",
            "Processing ch_ch09.txt (27 of 472 files)\n",
            "Processing cj_cj50.txt (28 of 472 files)\n",
            "Processing cm_cm05.txt (29 of 472 files)\n",
            "Processing cl_cl15.txt (30 of 472 files)\n",
            "Processing cj_cj21.txt (31 of 472 files)\n",
            "Processing cn_cn14.txt (32 of 472 files)\n",
            "Processing cp_cp09.txt (33 of 472 files)\n",
            "Processing cf_cf37.txt (34 of 472 files)\n",
            "Processing cg_cg11.txt (35 of 472 files)\n",
            "Processing ca_ca25.txt (36 of 472 files)\n",
            "Processing cl_cl11.txt (37 of 472 files)\n",
            "Processing ca_ca19.txt (38 of 472 files)\n",
            "Processing ch_ch24.txt (39 of 472 files)\n",
            "Processing cj_cj62.txt (40 of 472 files)\n",
            "Processing cn_cn11.txt (41 of 472 files)\n",
            "Processing cg_cg06.txt (42 of 472 files)\n",
            "Processing cb_cb08.txt (43 of 472 files)\n",
            "Processing cg_cg47.txt (44 of 472 files)\n",
            "Processing cf_cf38.txt (45 of 472 files)\n",
            "Processing cf_cf33.txt (46 of 472 files)\n",
            "Processing cb_cb04.txt (47 of 472 files)\n",
            "Processing cm_cm06.txt (48 of 472 files)\n",
            "Processing cg_cg70.txt (49 of 472 files)\n",
            "Processing cf_cf45.txt (50 of 472 files)\n",
            "Processing cf_cf16.txt (51 of 472 files)\n",
            "Processing cg_cg34.txt (52 of 472 files)\n",
            "Processing ck_ck21.txt (53 of 472 files)\n",
            "Processing cg_cg26.txt (54 of 472 files)\n",
            "Processing cg_cg08.txt (55 of 472 files)\n",
            "Processing cg_cg73.txt (56 of 472 files)\n",
            "Processing cg_cg37.txt (57 of 472 files)\n",
            "Processing cg_cg32.txt (58 of 472 files)\n",
            "Processing cn_cn03.txt (59 of 472 files)\n",
            "Processing cb_cb23.txt (60 of 472 files)\n",
            "Processing ce_ce20.txt (61 of 472 files)\n",
            "Processing cf_cf20.txt (62 of 472 files)\n",
            "Processing cj_cj09.txt (63 of 472 files)\n",
            "Processing cg_cg66.txt (64 of 472 files)\n",
            "Processing cj_cj69.txt (65 of 472 files)\n",
            "Processing ca_ca33.txt (66 of 472 files)\n",
            "Processing ca_ca04.txt (67 of 472 files)\n",
            "Processing cc_cc12.txt (68 of 472 files)\n",
            "Processing cj_cj63.txt (69 of 472 files)\n",
            "Processing cj_cj25.txt (70 of 472 files)\n",
            "Processing ca_ca30.txt (71 of 472 files)\n",
            "Processing cf_cf11.txt (72 of 472 files)\n",
            "Processing cp_cp06.txt (73 of 472 files)\n",
            "Processing ck_ck08.txt (74 of 472 files)\n",
            "Processing ce_ce10.txt (75 of 472 files)\n",
            "Processing cd_cd16.txt (76 of 472 files)\n",
            "Processing ca_ca42.txt (77 of 472 files)\n",
            "Processing ch_ch03.txt (78 of 472 files)\n",
            "Processing cj_cj78.txt (79 of 472 files)\n",
            "Processing cb_cb25.txt (80 of 472 files)\n",
            "Processing ca_ca15.txt (81 of 472 files)\n",
            "Processing cn_cn13.txt (82 of 472 files)\n",
            "Processing ck_ck17.txt (83 of 472 files)\n",
            "Processing cp_cp04.txt (84 of 472 files)\n",
            "Processing cf_cf39.txt (85 of 472 files)\n",
            "Processing cd_cd01.txt (86 of 472 files)\n",
            "Processing ce_ce31.txt (87 of 472 files)\n",
            "Processing ch_ch10.txt (88 of 472 files)\n",
            "Processing cd_cd14.txt (89 of 472 files)\n",
            "Processing cf_cf27.txt (90 of 472 files)\n",
            "Processing cj_cj72.txt (91 of 472 files)\n",
            "Processing cf_cf26.txt (92 of 472 files)\n",
            "Processing cg_cg29.txt (93 of 472 files)\n",
            "Processing ch_ch29.txt (94 of 472 files)\n",
            "Processing cf_cf03.txt (95 of 472 files)\n",
            "Processing cj_cj08.txt (96 of 472 files)\n",
            "Processing ch_ch21.txt (97 of 472 files)\n",
            "Processing cj_cj44.txt (98 of 472 files)\n",
            "Processing cj_cj02.txt (99 of 472 files)\n",
            "Processing cj_cj15.txt (100 of 472 files)\n",
            "Processing ch_ch19.txt (101 of 472 files)\n",
            "Processing cn_cn10.txt (102 of 472 files)\n",
            "Processing cj_cj12.txt (103 of 472 files)\n",
            "Processing cg_cg38.txt (104 of 472 files)\n",
            "Processing cj_cj34.txt (105 of 472 files)\n",
            "Processing cf_cf12.txt (106 of 472 files)\n",
            "Processing cj_cj70.txt (107 of 472 files)\n",
            "Processing cd_cd06.txt (108 of 472 files)\n",
            "Processing ce_ce28.txt (109 of 472 files)\n",
            "Processing ca_ca17.txt (110 of 472 files)\n",
            "Processing ch_ch17.txt (111 of 472 files)\n",
            "Processing cd_cd07.txt (112 of 472 files)\n",
            "Processing cg_cg60.txt (113 of 472 files)\n",
            "Processing ch_ch11.txt (114 of 472 files)\n",
            "Processing cf_cf31.txt (115 of 472 files)\n",
            "Processing cg_cg27.txt (116 of 472 files)\n",
            "Processing cb_cb22.txt (117 of 472 files)\n",
            "Processing cc_cc17.txt (118 of 472 files)\n",
            "Processing ce_ce02.txt (119 of 472 files)\n",
            "Processing cj_cj22.txt (120 of 472 files)\n",
            "Processing cj_cj38.txt (121 of 472 files)\n",
            "Processing ca_ca23.txt (122 of 472 files)\n",
            "Processing cl_cl08.txt (123 of 472 files)\n",
            "Processing cl_cl07.txt (124 of 472 files)\n",
            "Processing cb_cb17.txt (125 of 472 files)\n",
            "Processing cd_cd02.txt (126 of 472 files)\n",
            "Processing cg_cg30.txt (127 of 472 files)\n",
            "Processing cg_cg19.txt (128 of 472 files)\n",
            "Processing cg_cg31.txt (129 of 472 files)\n",
            "Processing cg_cg16.txt (130 of 472 files)\n",
            "Processing cc_cc13.txt (131 of 472 files)\n",
            "Processing ck_ck02.txt (132 of 472 files)\n",
            "Processing ca_ca29.txt (133 of 472 files)\n",
            "Processing cj_cj47.txt (134 of 472 files)\n",
            "Processing cd_cd12.txt (135 of 472 files)\n",
            "Processing ck_ck04.txt (136 of 472 files)\n",
            "Processing cl_cl13.txt (137 of 472 files)\n",
            "Processing cj_cj42.txt (138 of 472 files)\n",
            "Processing ck_ck25.txt (139 of 472 files)\n",
            "Processing cf_cf36.txt (140 of 472 files)\n",
            "Processing ch_ch23.txt (141 of 472 files)\n",
            "Processing cg_cg58.txt (142 of 472 files)\n",
            "Processing cd_cd09.txt (143 of 472 files)\n",
            "Processing cn_cn12.txt (144 of 472 files)\n",
            "Processing cn_cn25.txt (145 of 472 files)\n",
            "Processing cn_cn26.txt (146 of 472 files)\n",
            "Processing ce_ce18.txt (147 of 472 files)\n",
            "Processing ce_ce23.txt (148 of 472 files)\n",
            "Processing cf_cf47.txt (149 of 472 files)\n",
            "Processing cj_cj11.txt (150 of 472 files)\n",
            "Processing ca_ca38.txt (151 of 472 files)\n",
            "Processing cg_cg14.txt (152 of 472 files)\n",
            "Processing ch_ch22.txt (153 of 472 files)\n",
            "Processing ch_ch18.txt (154 of 472 files)\n",
            "Processing cc_cc05.txt (155 of 472 files)\n",
            "Processing cn_cn09.txt (156 of 472 files)\n",
            "Processing ca_ca37.txt (157 of 472 files)\n",
            "Processing cc_cc15.txt (158 of 472 files)\n",
            "Processing cj_cj10.txt (159 of 472 files)\n",
            "Processing cg_cg59.txt (160 of 472 files)\n",
            "Processing cc_cc16.txt (161 of 472 files)\n",
            "Processing ce_ce30.txt (162 of 472 files)\n",
            "Processing ch_ch30.txt (163 of 472 files)\n",
            "Processing ch_ch15.txt (164 of 472 files)\n",
            "Processing ch_ch28.txt (165 of 472 files)\n",
            "Processing ce_ce07.txt (166 of 472 files)\n",
            "Processing ca_ca03.txt (167 of 472 files)\n",
            "Processing cj_cj56.txt (168 of 472 files)\n",
            "Processing cl_cl03.txt (169 of 472 files)\n",
            "Processing cg_cg63.txt (170 of 472 files)\n",
            "Processing cl_cl02.txt (171 of 472 files)\n",
            "Processing ca_ca32.txt (172 of 472 files)\n",
            "Processing cj_cj13.txt (173 of 472 files)\n",
            "Processing cd_cd08.txt (174 of 472 files)\n",
            "Processing cj_cj71.txt (175 of 472 files)\n",
            "Processing ca_ca10.txt (176 of 472 files)\n",
            "Processing cn_cn16.txt (177 of 472 files)\n",
            "Processing cj_cj53.txt (178 of 472 files)\n",
            "Processing cp_cp07.txt (179 of 472 files)\n",
            "Processing ch_ch25.txt (180 of 472 files)\n",
            "Processing ca_ca31.txt (181 of 472 files)\n",
            "Processing cg_cg56.txt (182 of 472 files)\n",
            "Processing cf_cf18.txt (183 of 472 files)\n",
            "Processing cc_cc10.txt (184 of 472 files)\n",
            "Processing cf_cf09.txt (185 of 472 files)\n",
            "Processing ca_ca05.txt (186 of 472 files)\n",
            "Processing ch_ch01.txt (187 of 472 files)\n",
            "Processing cl_cl01.txt (188 of 472 files)\n",
            "Processing ca_ca13.txt (189 of 472 files)\n",
            "Processing cb_cb05.txt (190 of 472 files)\n",
            "Processing cc_cc11.txt (191 of 472 files)\n",
            "Processing ch_ch07.txt (192 of 472 files)\n",
            "Processing cj_cj14.txt (193 of 472 files)\n",
            "Processing cb_cb14.txt (194 of 472 files)\n",
            "Processing ck_ck05.txt (195 of 472 files)\n",
            "Processing cg_cg48.txt (196 of 472 files)\n",
            "Processing ca_ca34.txt (197 of 472 files)\n",
            "Processing cj_cj36.txt (198 of 472 files)\n",
            "Processing cf_cf25.txt (199 of 472 files)\n",
            "Processing ce_ce17.txt (200 of 472 files)\n",
            "Processing cj_cj80.txt (201 of 472 files)\n",
            "Processing cg_cg22.txt (202 of 472 files)\n",
            "Processing cj_cj26.txt (203 of 472 files)\n",
            "Processing cn_cn05.txt (204 of 472 files)\n",
            "Processing cl_cl20.txt (205 of 472 files)\n",
            "Processing ca_ca11.txt (206 of 472 files)\n",
            "Processing ce_ce04.txt (207 of 472 files)\n",
            "Processing cf_cf21.txt (208 of 472 files)\n",
            "Processing cg_cg07.txt (209 of 472 files)\n",
            "Processing cg_cg62.txt (210 of 472 files)\n",
            "Processing cd_cd10.txt (211 of 472 files)\n",
            "Processing cp_cp02.txt (212 of 472 files)\n",
            "Processing ca_ca44.txt (213 of 472 files)\n",
            "Processing cj_cj64.txt (214 of 472 files)\n",
            "Processing cj_cj32.txt (215 of 472 files)\n",
            "Processing cg_cg01.txt (216 of 472 files)\n",
            "Processing cn_cn07.txt (217 of 472 files)\n",
            "Processing cj_cj51.txt (218 of 472 files)\n",
            "Processing cj_cj75.txt (219 of 472 files)\n",
            "Processing cg_cg25.txt (220 of 472 files)\n",
            "Processing cb_cb02.txt (221 of 472 files)\n",
            "Processing cm_cm03.txt (222 of 472 files)\n",
            "Processing cf_cf46.txt (223 of 472 files)\n",
            "Processing ce_ce09.txt (224 of 472 files)\n",
            "Processing cd_cd13.txt (225 of 472 files)\n",
            "Processing cj_cj77.txt (226 of 472 files)\n",
            "Processing cf_cf05.txt (227 of 472 files)\n",
            "Processing ca_ca07.txt (228 of 472 files)\n",
            "Processing cb_cb24.txt (229 of 472 files)\n",
            "Processing cj_cj45.txt (230 of 472 files)\n",
            "Processing ck_ck06.txt (231 of 472 files)\n",
            "Processing cp_cp01.txt (232 of 472 files)\n",
            "Processing cg_cg46.txt (233 of 472 files)\n",
            "Processing cb_cb21.txt (234 of 472 files)\n",
            "Processing cj_cj40.txt (235 of 472 files)\n",
            "Processing ce_ce19.txt (236 of 472 files)\n",
            "Processing ck_ck19.txt (237 of 472 files)\n",
            "Processing ck_ck20.txt (238 of 472 files)\n",
            "Processing ca_ca39.txt (239 of 472 files)\n",
            "Processing ch_ch13.txt (240 of 472 files)\n",
            "Processing cj_cj61.txt (241 of 472 files)\n",
            "Processing cl_cl10.txt (242 of 472 files)\n",
            "Processing cf_cf44.txt (243 of 472 files)\n",
            "Processing ck_ck22.txt (244 of 472 files)\n",
            "Processing cn_cn24.txt (245 of 472 files)\n",
            "Processing ch_ch20.txt (246 of 472 files)\n",
            "Processing cn_cn19.txt (247 of 472 files)\n",
            "Processing cj_cj39.txt (248 of 472 files)\n",
            "Processing cb_cb07.txt (249 of 472 files)\n",
            "Processing cf_cf30.txt (250 of 472 files)\n",
            "Processing cf_cf06.txt (251 of 472 files)\n",
            "Processing cg_cg05.txt (252 of 472 files)\n",
            "Processing cf_cf23.txt (253 of 472 files)\n",
            "Processing cg_cg21.txt (254 of 472 files)\n",
            "Processing cb_cb18.txt (255 of 472 files)\n",
            "Processing cb_cb13.txt (256 of 472 files)\n",
            "Processing cd_cd17.txt (257 of 472 files)\n",
            "Processing cj_cj48.txt (258 of 472 files)\n",
            "Processing ce_ce11.txt (259 of 472 files)\n",
            "Processing cj_cj76.txt (260 of 472 files)\n",
            "Processing cj_cj46.txt (261 of 472 files)\n",
            "Processing cg_cg64.txt (262 of 472 files)\n",
            "Processing ce_ce13.txt (263 of 472 files)\n",
            "Processing cg_cg20.txt (264 of 472 files)\n",
            "Processing cb_cb15.txt (265 of 472 files)\n",
            "Processing ce_ce27.txt (266 of 472 files)\n",
            "Processing cf_cf40.txt (267 of 472 files)\n",
            "Processing cg_cg10.txt (268 of 472 files)\n",
            "Processing ch_ch06.txt (269 of 472 files)\n",
            "Processing cg_cg24.txt (270 of 472 files)\n",
            "Processing cj_cj66.txt (271 of 472 files)\n",
            "Processing ce_ce36.txt (272 of 472 files)\n",
            "Processing cc_cc09.txt (273 of 472 files)\n",
            "Processing cj_cj01.txt (274 of 472 files)\n",
            "Processing cj_cj67.txt (275 of 472 files)\n",
            "Processing cg_cg51.txt (276 of 472 files)\n",
            "Processing cb_cb10.txt (277 of 472 files)\n",
            "Processing cj_cj60.txt (278 of 472 files)\n",
            "Processing cj_cj18.txt (279 of 472 files)\n",
            "Processing cg_cg41.txt (280 of 472 files)\n",
            "Processing cj_cj23.txt (281 of 472 files)\n",
            "Processing cj_cj43.txt (282 of 472 files)\n",
            "Processing cc_cc08.txt (283 of 472 files)\n",
            "Processing cp_cp03.txt (284 of 472 files)\n",
            "Processing cj_cj58.txt (285 of 472 files)\n",
            "Processing cg_cg75.txt (286 of 472 files)\n",
            "Processing cg_cg67.txt (287 of 472 files)\n",
            "Processing cp_cp05.txt (288 of 472 files)\n",
            "Processing ce_ce05.txt (289 of 472 files)\n",
            "Processing cf_cf13.txt (290 of 472 files)\n",
            "Processing cm_cm04.txt (291 of 472 files)\n",
            "Processing cg_cg12.txt (292 of 472 files)\n",
            "Processing ch_ch08.txt (293 of 472 files)\n",
            "Processing cj_cj24.txt (294 of 472 files)\n",
            "Processing ce_ce34.txt (295 of 472 files)\n",
            "Processing ck_ck09.txt (296 of 472 files)\n",
            "Processing cd_cd11.txt (297 of 472 files)\n",
            "Processing cc_cc03.txt (298 of 472 files)\n",
            "Processing cf_cf34.txt (299 of 472 files)\n",
            "Processing ck_ck13.txt (300 of 472 files)\n",
            "Processing cj_cj33.txt (301 of 472 files)\n",
            "Processing ce_ce25.txt (302 of 472 files)\n",
            "Processing cj_cj41.txt (303 of 472 files)\n",
            "Processing ch_ch04.txt (304 of 472 files)\n",
            "Processing cg_cg09.txt (305 of 472 files)\n",
            "Processing ca_ca24.txt (306 of 472 files)\n",
            "Processing cj_cj06.txt (307 of 472 files)\n",
            "Processing cj_cj19.txt (308 of 472 files)\n",
            "Processing cg_cg45.txt (309 of 472 files)\n",
            "Processing cf_cf28.txt (310 of 472 files)\n",
            "Processing cn_cn02.txt (311 of 472 files)\n",
            "Processing cn_cn23.txt (312 of 472 files)\n",
            "Processing cj_cj55.txt (313 of 472 files)\n",
            "Processing cf_cf29.txt (314 of 472 files)\n",
            "Processing cg_cg18.txt (315 of 472 files)\n",
            "Processing cj_cj29.txt (316 of 472 files)\n",
            "Processing ck_ck23.txt (317 of 472 files)\n",
            "Processing ck_ck18.txt (318 of 472 files)\n",
            "Processing cn_cn04.txt (319 of 472 files)\n",
            "Processing cj_cj35.txt (320 of 472 files)\n",
            "Processing cb_cb19.txt (321 of 472 files)\n",
            "Processing cj_cj16.txt (322 of 472 files)\n",
            "Processing cn_cn20.txt (323 of 472 files)\n",
            "Processing cg_cg69.txt (324 of 472 files)\n",
            "Processing cf_cf17.txt (325 of 472 files)\n",
            "Processing ck_ck03.txt (326 of 472 files)\n",
            "Processing cj_cj05.txt (327 of 472 files)\n",
            "Processing cl_cl09.txt (328 of 472 files)\n",
            "Processing cj_cj49.txt (329 of 472 files)\n",
            "Processing cf_cf24.txt (330 of 472 files)\n",
            "Processing cj_cj31.txt (331 of 472 files)\n",
            "Processing cg_cg02.txt (332 of 472 files)\n",
            "Processing ch_ch05.txt (333 of 472 files)\n",
            "Processing cn_cn28.txt (334 of 472 files)\n",
            "Processing cf_cf07.txt (335 of 472 files)\n",
            "Processing cg_cg44.txt (336 of 472 files)\n",
            "Processing ck_ck14.txt (337 of 472 files)\n",
            "Processing cl_cl23.txt (338 of 472 files)\n",
            "Processing ce_ce24.txt (339 of 472 files)\n",
            "Processing cg_cg65.txt (340 of 472 files)\n",
            "Processing cj_cj68.txt (341 of 472 files)\n",
            "Processing cl_cl16.txt (342 of 472 files)\n",
            "Processing ca_ca02.txt (343 of 472 files)\n",
            "Processing cj_cj65.txt (344 of 472 files)\n",
            "Processing ca_ca40.txt (345 of 472 files)\n",
            "Processing ca_ca12.txt (346 of 472 files)\n",
            "Processing cj_cj28.txt (347 of 472 files)\n",
            "Processing ca_ca27.txt (348 of 472 files)\n",
            "Processing ce_ce33.txt (349 of 472 files)\n",
            "Processing cj_cj03.txt (350 of 472 files)\n",
            "Processing ca_ca18.txt (351 of 472 files)\n",
            "Processing cl_cl14.txt (352 of 472 files)\n",
            "Processing ce_ce15.txt (353 of 472 files)\n",
            "Processing ca_ca20.txt (354 of 472 files)\n",
            "Processing cf_cf19.txt (355 of 472 files)\n",
            "Processing cg_cg49.txt (356 of 472 files)\n",
            "Processing cj_cj27.txt (357 of 472 files)\n",
            "Processing cg_cg33.txt (358 of 472 files)\n",
            "Processing ca_ca26.txt (359 of 472 files)\n",
            "Processing cj_cj20.txt (360 of 472 files)\n",
            "Processing cj_cj07.txt (361 of 472 files)\n",
            "Processing ca_ca41.txt (362 of 472 files)\n",
            "Processing ch_ch27.txt (363 of 472 files)\n",
            "Processing cd_cd05.txt (364 of 472 files)\n",
            "Processing cg_cg54.txt (365 of 472 files)\n",
            "Processing cg_cg04.txt (366 of 472 files)\n",
            "Processing cb_cb06.txt (367 of 472 files)\n",
            "Processing cm_cm01.txt (368 of 472 files)\n",
            "Processing cj_cj57.txt (369 of 472 files)\n",
            "Processing cf_cf10.txt (370 of 472 files)\n",
            "Processing cn_cn15.txt (371 of 472 files)\n",
            "Processing ch_ch14.txt (372 of 472 files)\n",
            "Processing cg_cg57.txt (373 of 472 files)\n",
            "Processing cf_cf43.txt (374 of 472 files)\n",
            "Processing cf_cf48.txt (375 of 472 files)\n",
            "Processing cj_cj73.txt (376 of 472 files)\n",
            "Processing cb_cb16.txt (377 of 472 files)\n",
            "Processing cc_cc04.txt (378 of 472 files)\n",
            "Processing cg_cg40.txt (379 of 472 files)\n",
            "Processing cc_cc06.txt (380 of 472 files)\n",
            "Processing ch_ch02.txt (381 of 472 files)\n",
            "Processing cf_cf02.txt (382 of 472 files)\n",
            "Processing ck_ck29.txt (383 of 472 files)\n",
            "Processing cf_cf42.txt (384 of 472 files)\n",
            "Processing ca_ca09.txt (385 of 472 files)\n",
            "Processing cj_cj54.txt (386 of 472 files)\n",
            "Processing cd_cd15.txt (387 of 472 files)\n",
            "Processing cl_cl04.txt (388 of 472 files)\n",
            "Processing ck_ck24.txt (389 of 472 files)\n",
            "Processing ca_ca16.txt (390 of 472 files)\n",
            "Processing cl_cl17.txt (391 of 472 files)\n",
            "Processing ce_ce32.txt (392 of 472 files)\n",
            "Processing cg_cg52.txt (393 of 472 files)\n",
            "Processing cp_cp08.txt (394 of 472 files)\n",
            "Processing ck_ck07.txt (395 of 472 files)\n",
            "Processing cl_cl18.txt (396 of 472 files)\n",
            "Processing cl_cl05.txt (397 of 472 files)\n",
            "Processing cn_cn06.txt (398 of 472 files)\n",
            "Processing cj_cj74.txt (399 of 472 files)\n",
            "Processing cj_cj52.txt (400 of 472 files)\n",
            "Processing cg_cg42.txt (401 of 472 files)\n",
            "Processing cn_cn01.txt (402 of 472 files)\n",
            "Processing cb_cb26.txt (403 of 472 files)\n",
            "Processing cg_cg28.txt (404 of 472 files)\n",
            "Processing ck_ck15.txt (405 of 472 files)\n",
            "Processing cg_cg17.txt (406 of 472 files)\n",
            "Processing cg_cg13.txt (407 of 472 files)\n",
            "Processing ca_ca21.txt (408 of 472 files)\n",
            "Processing cc_cc01.txt (409 of 472 files)\n",
            "Processing cl_cl19.txt (410 of 472 files)\n",
            "Processing ca_ca14.txt (411 of 472 files)\n",
            "Processing cj_cj30.txt (412 of 472 files)\n",
            "Processing cf_cf08.txt (413 of 472 files)\n",
            "Processing ce_ce21.txt (414 of 472 files)\n",
            "Processing cg_cg55.txt (415 of 472 files)\n",
            "Processing cj_cj17.txt (416 of 472 files)\n",
            "Processing cg_cg74.txt (417 of 472 files)\n",
            "Processing cn_cn17.txt (418 of 472 files)\n",
            "Processing ca_ca36.txt (419 of 472 files)\n",
            "Processing cl_cl21.txt (420 of 472 files)\n",
            "Processing cb_cb09.txt (421 of 472 files)\n",
            "Processing cf_cf32.txt (422 of 472 files)\n",
            "Processing cg_cg72.txt (423 of 472 files)\n",
            "Processing ca_ca43.txt (424 of 472 files)\n",
            "Processing cn_cn22.txt (425 of 472 files)\n",
            "Processing cj_cj37.txt (426 of 472 files)\n",
            "Processing cj_cj04.txt (427 of 472 files)\n",
            "Processing cf_cf04.txt (428 of 472 files)\n",
            "Processing ca_ca22.txt (429 of 472 files)\n",
            "Processing cn_cn18.txt (430 of 472 files)\n",
            "Processing cc_cc07.txt (431 of 472 files)\n",
            "Processing cg_cg36.txt (432 of 472 files)\n",
            "Processing cc_cc14.txt (433 of 472 files)\n",
            "Processing ca_ca08.txt (434 of 472 files)\n",
            "Processing ck_ck28.txt (435 of 472 files)\n",
            "Processing cg_cg43.txt (436 of 472 files)\n",
            "Processing cf_cf14.txt (437 of 472 files)\n",
            "Processing ce_ce06.txt (438 of 472 files)\n",
            "Processing ce_ce12.txt (439 of 472 files)\n",
            "Processing cb_cb12.txt (440 of 472 files)\n",
            "Processing cn_cn29.txt (441 of 472 files)\n",
            "Processing cj_cj79.txt (442 of 472 files)\n",
            "Processing ch_ch16.txt (443 of 472 files)\n",
            "Processing ck_ck01.txt (444 of 472 files)\n",
            "Processing cf_cf01.txt (445 of 472 files)\n",
            "Processing cj_cj59.txt (446 of 472 files)\n",
            "Processing cl_cl24.txt (447 of 472 files)\n",
            "Processing cg_cg03.txt (448 of 472 files)\n",
            "Processing ca_ca35.txt (449 of 472 files)\n",
            "Processing ch_ch12.txt (450 of 472 files)\n",
            "Processing cm_cm02.txt (451 of 472 files)\n",
            "Processing ce_ce29.txt (452 of 472 files)\n",
            "Processing cg_cg61.txt (453 of 472 files)\n",
            "Processing cf_cf22.txt (454 of 472 files)\n",
            "Processing ce_ce01.txt (455 of 472 files)\n",
            "Processing cb_cb20.txt (456 of 472 files)\n",
            "Processing ce_ce14.txt (457 of 472 files)\n",
            "Processing cd_cd03.txt (458 of 472 files)\n",
            "Processing cb_cb01.txt (459 of 472 files)\n",
            "Processing cf_cf41.txt (460 of 472 files)\n",
            "Processing ce_ce08.txt (461 of 472 files)\n",
            "Processing cg_cg23.txt (462 of 472 files)\n",
            "Processing cg_cg50.txt (463 of 472 files)\n",
            "Processing ce_ce16.txt (464 of 472 files)\n",
            "Processing cg_cg71.txt (465 of 472 files)\n",
            "Processing ca_ca06.txt (466 of 472 files)\n",
            "Processing cg_cg53.txt (467 of 472 files)\n",
            "Processing ce_ce35.txt (468 of 472 files)\n",
            "Processing ck_ck11.txt (469 of 472 files)\n",
            "Processing ce_ce03.txt (470 of 472 files)\n",
            "Processing cl_cl06.txt (471 of 472 files)\n",
            "Processing cd_cd04.txt (472 of 472 files)\n",
            "Search returned 4 hits.\n",
            " Returning all 4 hits\n",
            "[['s', 'nest', 'to', 'the', 'rocky', 'ribs', 'of', 'the', 'canyonside', 'russ'], 'ran', ['up', 'the', 'steps', 'quickly', 'to', 'the', 'plank', 'porch', 'the', 'front']]\n",
            "[['range', 'and', 'in', 'marlin', 's', 'underground', 'test', 'gallery', 'we', 'quickly'], 'ran', ['into', 'the', 'same', 'trouble', 'that', 'plagued', 'bill', 'ruger', 'in', 'his']]\n",
            "[['hands', 'and', 'feet', 'keeping', 'the', 'hands', 'in', 'the', 'starting', 'position'], 'run', ['in', 'place', 'to', 'a', 'quick', 'rhythm', 'after', 'this', 'has', 'become']]\n",
            "[['engine', 'up', 'to', 'operating', 'temperature', 'quickly', 'and', 'to', 'keep', 'it'], 'running', ['at', 'its', 'most', 'efficient', 'temperature', 'through', 'the', 'proper', 'circulation', 'of']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Search terms (and collocate search terms) can also be interpreted as regular expressions:"
      ],
      "metadata": {
        "id": "VsgoiqmtEJmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conc_results3 = ct.concord(ct.tokenize(ct.ldcorpus(\"brown_single\"),lemma = False),[\"run.*\",\"ran\"],collocates = [\"quick.*\"], nhits = 10, regex = True)\n",
        "for x in conc_results3:\n",
        "\tprint(x)"
      ],
      "metadata": {
        "id": "a6anqCqcEUGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a tagged version of your corpus\n",
        "The most efficient way to conduct multiple analyses with a tagged corpus is to write a tagged version of your corpus to file and then conduct subsequent analyses with the tagged files. If this is not possible for some reason, one can always run the tagger each time an analysis is conducted."
      ],
      "metadata": {
        "id": "dHGE9T_iEqCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tagged_brown = ct.tag(ct.ldcorpus(\"brown_single\"))\n",
        "# ct.write_corpus(\"tagged_brown_single\",tagged_brown) \n",
        "#the first argument is the folder where the tagged files will be written"
      ],
      "metadata": {
        "id": "HyVM_GgxEkx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The function tag() is also a Python generator, so the preferred way to write a corpus is:"
      ],
      "metadata": {
        "id": "_8lcRr-XFFKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ct.write_corpus(\"tagged_brown_single\",ct.tag(ct.ldcorpus(\"brown_single\")))"
      ],
      "metadata": {
        "id": "BmNc4hyxFCD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Now, we can reload our tagged corpus using the reload() function and generate a part of speech sensitive frequency list."
      ],
      "metadata": {
        "id": "cPskzsI0FKza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_freq = ct.frequency(ct.reload(\"tagged_brown_single\"))\n",
        "ct.head(tagged_freq, hits = 10)"
      ],
      "metadata": {
        "id": "eU1OLQMgFNLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collocation: \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "=> Use the collocator() function to find collocates for a particular word."
      ],
      "metadata": {
        "id": "hMi20M0CFZVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "collocates = ct.collocator(ct.tokenize(ct.ldcorpus(\"brown_single\")),\"go\",stat = \"MI\")\n",
        "#stat options include: \"MI\", \"T\", \"freq\", \"left\", and \"right\"\n",
        "\n",
        "ct.head(collocates, hits = 10)"
      ],
      "metadata": {
        "id": "mUOQTQ9jFbb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keyness\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Keyness is calculated using two frequency dictionaries (consisting of raw frequency values). Only effect sizes are reported (p values are arguably not particularly useful for keyness analyses). Keyness calculation options include \"log-ratio\", \"%diff\", and \"odds-ratio\"."
      ],
      "metadata": {
        "id": "yENGGuKgF-XD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk.corpus\n",
        "nltk.download('brown')\n",
        "nltk.download('gutenberg')\n",
        "from nltk.corpus import gutenberg\n",
        "from nltk.corpus import brown\n",
        "print(\", \".join(brown.words()))"
      ],
      "metadata": {
        "id": "S73NEvn7H6sX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.corpus.brown.words()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdXpD7nYIfGK",
        "outputId": "ab820211-2d71-4e8c-ff99-3f54eca3dba3"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#First, generate frequency lists for each corpus\n",
        "corp1freq = ct.frequency(ct.tokenize(ct.ldcorpus(\"brown\")))\n",
        "corp2freq = ct.frequency(ct.tokenize(ct.ldcorpus(\"gutenberg\")))\n",
        "\n",
        "#then calculate Keyness\n",
        "corp_key = ct.keyness(corp1freq,corp2freq, effect = \"log-ratio\")\n",
        "ct.head(corp_key, hits = 10) #to display top hits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tUx7DZcGAyw",
        "outputId": "6bf13a4a-59c8-4882-cba5-90de7ac787f0"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No files found. There may be a problem with your working directory or your file search term.\n",
            "No files found. There may be a problem with your working directory or your file search term.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4H3RjSZJWHb",
        "outputId": "11f11574-0b91-4ea2-bade-30a22a47463a"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mynltkdata\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/mynltkdata/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCeLijU3JhL9",
        "outputId": "b1ec7b46-e8cd-4ce6-ac4f-964b82c53812"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mynltkdata\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# N-grams\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "N-grams are contiguous sequences of n words. The tokenize() function can be used to create an n-gram version of a corpus by employing the ngram argument. By default, words in an n-gram are separated by two underscores \"__\""
      ],
      "metadata": {
        "id": "BDC0Yu1LGK1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trigramfreq = ct.frequency(ct.tokenize(ct.ldcorpus(\"brown_single\"),lemma = False, ngram = 3))"
      ],
      "metadata": {
        "id": "_D_QCEsYGN-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ct.head(trigramfreq, hits = 10)"
      ],
      "metadata": {
        "id": "1DvTLuvuKISM",
        "outputId": "cc3b6353-2a1b-4efa-d160-b74d6b97f94f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "one__of__the\t390\n",
            "the__united__states\t339\n",
            "as__well__as\t233\n",
            "some__of__the\t174\n",
            "the__fact__that\t164\n",
            "out__of__the\t159\n",
            "part__of__the\t142\n",
            "the__end__of\t140\n",
            "i__do__nt\t139\n",
            "it__is__not\t131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependency bigrams\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Dependency bigrams consist of two words that are syntactically connected via a head-dependent relationship. For example, in the clause \"The player kicked the ball\", the main verb kicked is connected to the noun ball via a direct object relationship, wherein kicked is the head and ball is the dependent.\n",
        "\n",
        "The function dep_bigram() generates frequency dictionaries for the dependent, the head, and the dependency bigram. In addition, range is calculated along with a complete list of sentences in which the relationship occurs."
      ],
      "metadata": {
        "id": "LfMR6EjTGT2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bg_dict = ct.dep_bigram(ct.ldcorpus(\"brown_single\"),\"dobj\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMRTHnolGXZK",
        "outputId": "530fb8a2-fd60-4bd5-8eb4-80aa080aed15"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing cb_cb27.txt (1 of 472 files)\n",
            "Processing ca_ca28.txt (2 of 472 files)\n",
            "Processing ck_ck26.txt (3 of 472 files)\n",
            "Processing cb_cb03.txt (4 of 472 files)\n",
            "Processing cn_cn27.txt (5 of 472 files)\n",
            "Processing cn_cn21.txt (6 of 472 files)\n",
            "Processing cg_cg39.txt (7 of 472 files)\n",
            "Processing cg_cg15.txt (8 of 472 files)\n",
            "Processing cg_cg68.txt (9 of 472 files)\n",
            "Processing ce_ce26.txt (10 of 472 files)\n",
            "Processing ck_ck27.txt (11 of 472 files)\n",
            "Processing cl_cl12.txt (12 of 472 files)\n",
            "Processing cb_cb11.txt (13 of 472 files)\n",
            "Processing cf_cf15.txt (14 of 472 files)\n",
            "Processing cf_cf35.txt (15 of 472 files)\n",
            "Processing ck_ck12.txt (16 of 472 files)\n",
            "Processing ck_ck10.txt (17 of 472 files)\n",
            "Processing cp_cp10.txt (18 of 472 files)\n",
            "Processing cc_cc02.txt (19 of 472 files)\n",
            "Processing cg_cg35.txt (20 of 472 files)\n",
            "Processing ck_ck16.txt (21 of 472 files)\n",
            "Processing ca_ca01.txt (22 of 472 files)\n",
            "Processing ch_ch26.txt (23 of 472 files)\n",
            "Processing cn_cn08.txt (24 of 472 files)\n",
            "Processing cl_cl22.txt (25 of 472 files)\n",
            "Processing ce_ce22.txt (26 of 472 files)\n",
            "Processing ch_ch09.txt (27 of 472 files)\n",
            "Processing cj_cj50.txt (28 of 472 files)\n",
            "Processing cm_cm05.txt (29 of 472 files)\n",
            "Processing cl_cl15.txt (30 of 472 files)\n",
            "Processing cj_cj21.txt (31 of 472 files)\n",
            "Processing cn_cn14.txt (32 of 472 files)\n",
            "Processing cp_cp09.txt (33 of 472 files)\n",
            "Processing cf_cf37.txt (34 of 472 files)\n",
            "Processing cg_cg11.txt (35 of 472 files)\n",
            "Processing ca_ca25.txt (36 of 472 files)\n",
            "Processing cl_cl11.txt (37 of 472 files)\n",
            "Processing ca_ca19.txt (38 of 472 files)\n",
            "Processing ch_ch24.txt (39 of 472 files)\n",
            "Processing cj_cj62.txt (40 of 472 files)\n",
            "Processing cn_cn11.txt (41 of 472 files)\n",
            "Processing cg_cg06.txt (42 of 472 files)\n",
            "Processing cb_cb08.txt (43 of 472 files)\n",
            "Processing cg_cg47.txt (44 of 472 files)\n",
            "Processing cf_cf38.txt (45 of 472 files)\n",
            "Processing cf_cf33.txt (46 of 472 files)\n",
            "Processing cb_cb04.txt (47 of 472 files)\n",
            "Processing cm_cm06.txt (48 of 472 files)\n",
            "Processing cg_cg70.txt (49 of 472 files)\n",
            "Processing cf_cf45.txt (50 of 472 files)\n",
            "Processing cf_cf16.txt (51 of 472 files)\n",
            "Processing cg_cg34.txt (52 of 472 files)\n",
            "Processing ck_ck21.txt (53 of 472 files)\n",
            "Processing cg_cg26.txt (54 of 472 files)\n",
            "Processing cg_cg08.txt (55 of 472 files)\n",
            "Processing cg_cg73.txt (56 of 472 files)\n",
            "Processing cg_cg37.txt (57 of 472 files)\n",
            "Processing cg_cg32.txt (58 of 472 files)\n",
            "Processing cn_cn03.txt (59 of 472 files)\n",
            "Processing cb_cb23.txt (60 of 472 files)\n",
            "Processing ce_ce20.txt (61 of 472 files)\n",
            "Processing cf_cf20.txt (62 of 472 files)\n",
            "Processing cj_cj09.txt (63 of 472 files)\n",
            "Processing cg_cg66.txt (64 of 472 files)\n",
            "Processing cj_cj69.txt (65 of 472 files)\n",
            "Processing ca_ca33.txt (66 of 472 files)\n",
            "Processing ca_ca04.txt (67 of 472 files)\n",
            "Processing cc_cc12.txt (68 of 472 files)\n",
            "Processing cj_cj63.txt (69 of 472 files)\n",
            "Processing cj_cj25.txt (70 of 472 files)\n",
            "Processing ca_ca30.txt (71 of 472 files)\n",
            "Processing cf_cf11.txt (72 of 472 files)\n",
            "Processing cp_cp06.txt (73 of 472 files)\n",
            "Processing ck_ck08.txt (74 of 472 files)\n",
            "Processing ce_ce10.txt (75 of 472 files)\n",
            "Processing cd_cd16.txt (76 of 472 files)\n",
            "Processing ca_ca42.txt (77 of 472 files)\n",
            "Processing ch_ch03.txt (78 of 472 files)\n",
            "Processing cj_cj78.txt (79 of 472 files)\n",
            "Processing cb_cb25.txt (80 of 472 files)\n",
            "Processing ca_ca15.txt (81 of 472 files)\n",
            "Processing cn_cn13.txt (82 of 472 files)\n",
            "Processing ck_ck17.txt (83 of 472 files)\n",
            "Processing cp_cp04.txt (84 of 472 files)\n",
            "Processing cf_cf39.txt (85 of 472 files)\n",
            "Processing cd_cd01.txt (86 of 472 files)\n",
            "Processing ce_ce31.txt (87 of 472 files)\n",
            "Processing ch_ch10.txt (88 of 472 files)\n",
            "Processing cd_cd14.txt (89 of 472 files)\n",
            "Processing cf_cf27.txt (90 of 472 files)\n",
            "Processing cj_cj72.txt (91 of 472 files)\n",
            "Processing cf_cf26.txt (92 of 472 files)\n",
            "Processing cg_cg29.txt (93 of 472 files)\n",
            "Processing ch_ch29.txt (94 of 472 files)\n",
            "Processing cf_cf03.txt (95 of 472 files)\n",
            "Processing cj_cj08.txt (96 of 472 files)\n",
            "Processing ch_ch21.txt (97 of 472 files)\n",
            "Processing cj_cj44.txt (98 of 472 files)\n",
            "Processing cj_cj02.txt (99 of 472 files)\n",
            "Processing cj_cj15.txt (100 of 472 files)\n",
            "Processing ch_ch19.txt (101 of 472 files)\n",
            "Processing cn_cn10.txt (102 of 472 files)\n",
            "Processing cj_cj12.txt (103 of 472 files)\n",
            "Processing cg_cg38.txt (104 of 472 files)\n",
            "Processing cj_cj34.txt (105 of 472 files)\n",
            "Processing cf_cf12.txt (106 of 472 files)\n",
            "Processing cj_cj70.txt (107 of 472 files)\n",
            "Processing cd_cd06.txt (108 of 472 files)\n",
            "Processing ce_ce28.txt (109 of 472 files)\n",
            "Processing ca_ca17.txt (110 of 472 files)\n",
            "Processing ch_ch17.txt (111 of 472 files)\n",
            "Processing cd_cd07.txt (112 of 472 files)\n",
            "Processing cg_cg60.txt (113 of 472 files)\n",
            "Processing ch_ch11.txt (114 of 472 files)\n",
            "Processing cf_cf31.txt (115 of 472 files)\n",
            "Processing cg_cg27.txt (116 of 472 files)\n",
            "Processing cb_cb22.txt (117 of 472 files)\n",
            "Processing cc_cc17.txt (118 of 472 files)\n",
            "Processing ce_ce02.txt (119 of 472 files)\n",
            "Processing cj_cj22.txt (120 of 472 files)\n",
            "Processing cj_cj38.txt (121 of 472 files)\n",
            "Processing ca_ca23.txt (122 of 472 files)\n",
            "Processing cl_cl08.txt (123 of 472 files)\n",
            "Processing cl_cl07.txt (124 of 472 files)\n",
            "Processing cb_cb17.txt (125 of 472 files)\n",
            "Processing cd_cd02.txt (126 of 472 files)\n",
            "Processing cg_cg30.txt (127 of 472 files)\n",
            "Processing cg_cg19.txt (128 of 472 files)\n",
            "Processing cg_cg31.txt (129 of 472 files)\n",
            "Processing cg_cg16.txt (130 of 472 files)\n",
            "Processing cc_cc13.txt (131 of 472 files)\n",
            "Processing ck_ck02.txt (132 of 472 files)\n",
            "Processing ca_ca29.txt (133 of 472 files)\n",
            "Processing cj_cj47.txt (134 of 472 files)\n",
            "Processing cd_cd12.txt (135 of 472 files)\n",
            "Processing ck_ck04.txt (136 of 472 files)\n",
            "Processing cl_cl13.txt (137 of 472 files)\n",
            "Processing cj_cj42.txt (138 of 472 files)\n",
            "Processing ck_ck25.txt (139 of 472 files)\n",
            "Processing cf_cf36.txt (140 of 472 files)\n",
            "Processing ch_ch23.txt (141 of 472 files)\n",
            "Processing cg_cg58.txt (142 of 472 files)\n",
            "Processing cd_cd09.txt (143 of 472 files)\n",
            "Processing cn_cn12.txt (144 of 472 files)\n",
            "Processing cn_cn25.txt (145 of 472 files)\n",
            "Processing cn_cn26.txt (146 of 472 files)\n",
            "Processing ce_ce18.txt (147 of 472 files)\n",
            "Processing ce_ce23.txt (148 of 472 files)\n",
            "Processing cf_cf47.txt (149 of 472 files)\n",
            "Processing cj_cj11.txt (150 of 472 files)\n",
            "Processing ca_ca38.txt (151 of 472 files)\n",
            "Processing cg_cg14.txt (152 of 472 files)\n",
            "Processing ch_ch22.txt (153 of 472 files)\n",
            "Processing ch_ch18.txt (154 of 472 files)\n",
            "Processing cc_cc05.txt (155 of 472 files)\n",
            "Processing cn_cn09.txt (156 of 472 files)\n",
            "Processing ca_ca37.txt (157 of 472 files)\n",
            "Processing cc_cc15.txt (158 of 472 files)\n",
            "Processing cj_cj10.txt (159 of 472 files)\n",
            "Processing cg_cg59.txt (160 of 472 files)\n",
            "Processing cc_cc16.txt (161 of 472 files)\n",
            "Processing ce_ce30.txt (162 of 472 files)\n",
            "Processing ch_ch30.txt (163 of 472 files)\n",
            "Processing ch_ch15.txt (164 of 472 files)\n",
            "Processing ch_ch28.txt (165 of 472 files)\n",
            "Processing ce_ce07.txt (166 of 472 files)\n",
            "Processing ca_ca03.txt (167 of 472 files)\n",
            "Processing cj_cj56.txt (168 of 472 files)\n",
            "Processing cl_cl03.txt (169 of 472 files)\n",
            "Processing cg_cg63.txt (170 of 472 files)\n",
            "Processing cl_cl02.txt (171 of 472 files)\n",
            "Processing ca_ca32.txt (172 of 472 files)\n",
            "Processing cj_cj13.txt (173 of 472 files)\n",
            "Processing cd_cd08.txt (174 of 472 files)\n",
            "Processing cj_cj71.txt (175 of 472 files)\n",
            "Processing ca_ca10.txt (176 of 472 files)\n",
            "Processing cn_cn16.txt (177 of 472 files)\n",
            "Processing cj_cj53.txt (178 of 472 files)\n",
            "Processing cp_cp07.txt (179 of 472 files)\n",
            "Processing ch_ch25.txt (180 of 472 files)\n",
            "Processing ca_ca31.txt (181 of 472 files)\n",
            "Processing cg_cg56.txt (182 of 472 files)\n",
            "Processing cf_cf18.txt (183 of 472 files)\n",
            "Processing cc_cc10.txt (184 of 472 files)\n",
            "Processing cf_cf09.txt (185 of 472 files)\n",
            "Processing ca_ca05.txt (186 of 472 files)\n",
            "Processing ch_ch01.txt (187 of 472 files)\n",
            "Processing cl_cl01.txt (188 of 472 files)\n",
            "Processing ca_ca13.txt (189 of 472 files)\n",
            "Processing cb_cb05.txt (190 of 472 files)\n",
            "Processing cc_cc11.txt (191 of 472 files)\n",
            "Processing ch_ch07.txt (192 of 472 files)\n",
            "Processing cj_cj14.txt (193 of 472 files)\n",
            "Processing cb_cb14.txt (194 of 472 files)\n",
            "Processing ck_ck05.txt (195 of 472 files)\n",
            "Processing cg_cg48.txt (196 of 472 files)\n",
            "Processing ca_ca34.txt (197 of 472 files)\n",
            "Processing cj_cj36.txt (198 of 472 files)\n",
            "Processing cf_cf25.txt (199 of 472 files)\n",
            "Processing ce_ce17.txt (200 of 472 files)\n",
            "Processing cj_cj80.txt (201 of 472 files)\n",
            "Processing cg_cg22.txt (202 of 472 files)\n",
            "Processing cj_cj26.txt (203 of 472 files)\n",
            "Processing cn_cn05.txt (204 of 472 files)\n",
            "Processing cl_cl20.txt (205 of 472 files)\n",
            "Processing ca_ca11.txt (206 of 472 files)\n",
            "Processing ce_ce04.txt (207 of 472 files)\n",
            "Processing cf_cf21.txt (208 of 472 files)\n",
            "Processing cg_cg07.txt (209 of 472 files)\n",
            "Processing cg_cg62.txt (210 of 472 files)\n",
            "Processing cd_cd10.txt (211 of 472 files)\n",
            "Processing cp_cp02.txt (212 of 472 files)\n",
            "Processing ca_ca44.txt (213 of 472 files)\n",
            "Processing cj_cj64.txt (214 of 472 files)\n",
            "Processing cj_cj32.txt (215 of 472 files)\n",
            "Processing cg_cg01.txt (216 of 472 files)\n",
            "Processing cn_cn07.txt (217 of 472 files)\n",
            "Processing cj_cj51.txt (218 of 472 files)\n",
            "Processing cj_cj75.txt (219 of 472 files)\n",
            "Processing cg_cg25.txt (220 of 472 files)\n",
            "Processing cb_cb02.txt (221 of 472 files)\n",
            "Processing cm_cm03.txt (222 of 472 files)\n",
            "Processing cf_cf46.txt (223 of 472 files)\n",
            "Processing ce_ce09.txt (224 of 472 files)\n",
            "Processing cd_cd13.txt (225 of 472 files)\n",
            "Processing cj_cj77.txt (226 of 472 files)\n",
            "Processing cf_cf05.txt (227 of 472 files)\n",
            "Processing ca_ca07.txt (228 of 472 files)\n",
            "Processing cb_cb24.txt (229 of 472 files)\n",
            "Processing cj_cj45.txt (230 of 472 files)\n",
            "Processing ck_ck06.txt (231 of 472 files)\n",
            "Processing cp_cp01.txt (232 of 472 files)\n",
            "Processing cg_cg46.txt (233 of 472 files)\n",
            "Processing cb_cb21.txt (234 of 472 files)\n",
            "Processing cj_cj40.txt (235 of 472 files)\n",
            "Processing ce_ce19.txt (236 of 472 files)\n",
            "Processing ck_ck19.txt (237 of 472 files)\n",
            "Processing ck_ck20.txt (238 of 472 files)\n",
            "Processing ca_ca39.txt (239 of 472 files)\n",
            "Processing ch_ch13.txt (240 of 472 files)\n",
            "Processing cj_cj61.txt (241 of 472 files)\n",
            "Processing cl_cl10.txt (242 of 472 files)\n",
            "Processing cf_cf44.txt (243 of 472 files)\n",
            "Processing ck_ck22.txt (244 of 472 files)\n",
            "Processing cn_cn24.txt (245 of 472 files)\n",
            "Processing ch_ch20.txt (246 of 472 files)\n",
            "Processing cn_cn19.txt (247 of 472 files)\n",
            "Processing cj_cj39.txt (248 of 472 files)\n",
            "Processing cb_cb07.txt (249 of 472 files)\n",
            "Processing cf_cf30.txt (250 of 472 files)\n",
            "Processing cf_cf06.txt (251 of 472 files)\n",
            "Processing cg_cg05.txt (252 of 472 files)\n",
            "Processing cf_cf23.txt (253 of 472 files)\n",
            "Processing cg_cg21.txt (254 of 472 files)\n",
            "Processing cb_cb18.txt (255 of 472 files)\n",
            "Processing cb_cb13.txt (256 of 472 files)\n",
            "Processing cd_cd17.txt (257 of 472 files)\n",
            "Processing cj_cj48.txt (258 of 472 files)\n",
            "Processing ce_ce11.txt (259 of 472 files)\n",
            "Processing cj_cj76.txt (260 of 472 files)\n",
            "Processing cj_cj46.txt (261 of 472 files)\n",
            "Processing cg_cg64.txt (262 of 472 files)\n",
            "Processing ce_ce13.txt (263 of 472 files)\n",
            "Processing cg_cg20.txt (264 of 472 files)\n",
            "Processing cb_cb15.txt (265 of 472 files)\n",
            "Processing ce_ce27.txt (266 of 472 files)\n",
            "Processing cf_cf40.txt (267 of 472 files)\n",
            "Processing cg_cg10.txt (268 of 472 files)\n",
            "Processing ch_ch06.txt (269 of 472 files)\n",
            "Processing cg_cg24.txt (270 of 472 files)\n",
            "Processing cj_cj66.txt (271 of 472 files)\n",
            "Processing ce_ce36.txt (272 of 472 files)\n",
            "Processing cc_cc09.txt (273 of 472 files)\n",
            "Processing cj_cj01.txt (274 of 472 files)\n",
            "Processing cj_cj67.txt (275 of 472 files)\n",
            "Processing cg_cg51.txt (276 of 472 files)\n",
            "Processing cb_cb10.txt (277 of 472 files)\n",
            "Processing cj_cj60.txt (278 of 472 files)\n",
            "Processing cj_cj18.txt (279 of 472 files)\n",
            "Processing cg_cg41.txt (280 of 472 files)\n",
            "Processing cj_cj23.txt (281 of 472 files)\n",
            "Processing cj_cj43.txt (282 of 472 files)\n",
            "Processing cc_cc08.txt (283 of 472 files)\n",
            "Processing cp_cp03.txt (284 of 472 files)\n",
            "Processing cj_cj58.txt (285 of 472 files)\n",
            "Processing cg_cg75.txt (286 of 472 files)\n",
            "Processing cg_cg67.txt (287 of 472 files)\n",
            "Processing cp_cp05.txt (288 of 472 files)\n",
            "Processing ce_ce05.txt (289 of 472 files)\n",
            "Processing cf_cf13.txt (290 of 472 files)\n",
            "Processing cm_cm04.txt (291 of 472 files)\n",
            "Processing cg_cg12.txt (292 of 472 files)\n",
            "Processing ch_ch08.txt (293 of 472 files)\n",
            "Processing cj_cj24.txt (294 of 472 files)\n",
            "Processing ce_ce34.txt (295 of 472 files)\n",
            "Processing ck_ck09.txt (296 of 472 files)\n",
            "Processing cd_cd11.txt (297 of 472 files)\n",
            "Processing cc_cc03.txt (298 of 472 files)\n",
            "Processing cf_cf34.txt (299 of 472 files)\n",
            "Processing ck_ck13.txt (300 of 472 files)\n",
            "Processing cj_cj33.txt (301 of 472 files)\n",
            "Processing ce_ce25.txt (302 of 472 files)\n",
            "Processing cj_cj41.txt (303 of 472 files)\n",
            "Processing ch_ch04.txt (304 of 472 files)\n",
            "Processing cg_cg09.txt (305 of 472 files)\n",
            "Processing ca_ca24.txt (306 of 472 files)\n",
            "Processing cj_cj06.txt (307 of 472 files)\n",
            "Processing cj_cj19.txt (308 of 472 files)\n",
            "Processing cg_cg45.txt (309 of 472 files)\n",
            "Processing cf_cf28.txt (310 of 472 files)\n",
            "Processing cn_cn02.txt (311 of 472 files)\n",
            "Processing cn_cn23.txt (312 of 472 files)\n",
            "Processing cj_cj55.txt (313 of 472 files)\n",
            "Processing cf_cf29.txt (314 of 472 files)\n",
            "Processing cg_cg18.txt (315 of 472 files)\n",
            "Processing cj_cj29.txt (316 of 472 files)\n",
            "Processing ck_ck23.txt (317 of 472 files)\n",
            "Processing ck_ck18.txt (318 of 472 files)\n",
            "Processing cn_cn04.txt (319 of 472 files)\n",
            "Processing cj_cj35.txt (320 of 472 files)\n",
            "Processing cb_cb19.txt (321 of 472 files)\n",
            "Processing cj_cj16.txt (322 of 472 files)\n",
            "Processing cn_cn20.txt (323 of 472 files)\n",
            "Processing cg_cg69.txt (324 of 472 files)\n",
            "Processing cf_cf17.txt (325 of 472 files)\n",
            "Processing ck_ck03.txt (326 of 472 files)\n",
            "Processing cj_cj05.txt (327 of 472 files)\n",
            "Processing cl_cl09.txt (328 of 472 files)\n",
            "Processing cj_cj49.txt (329 of 472 files)\n",
            "Processing cf_cf24.txt (330 of 472 files)\n",
            "Processing cj_cj31.txt (331 of 472 files)\n",
            "Processing cg_cg02.txt (332 of 472 files)\n",
            "Processing ch_ch05.txt (333 of 472 files)\n",
            "Processing cn_cn28.txt (334 of 472 files)\n",
            "Processing cf_cf07.txt (335 of 472 files)\n",
            "Processing cg_cg44.txt (336 of 472 files)\n",
            "Processing ck_ck14.txt (337 of 472 files)\n",
            "Processing cl_cl23.txt (338 of 472 files)\n",
            "Processing ce_ce24.txt (339 of 472 files)\n",
            "Processing cg_cg65.txt (340 of 472 files)\n",
            "Processing cj_cj68.txt (341 of 472 files)\n",
            "Processing cl_cl16.txt (342 of 472 files)\n",
            "Processing ca_ca02.txt (343 of 472 files)\n",
            "Processing cj_cj65.txt (344 of 472 files)\n",
            "Processing ca_ca40.txt (345 of 472 files)\n",
            "Processing ca_ca12.txt (346 of 472 files)\n",
            "Processing cj_cj28.txt (347 of 472 files)\n",
            "Processing ca_ca27.txt (348 of 472 files)\n",
            "Processing ce_ce33.txt (349 of 472 files)\n",
            "Processing cj_cj03.txt (350 of 472 files)\n",
            "Processing ca_ca18.txt (351 of 472 files)\n",
            "Processing cl_cl14.txt (352 of 472 files)\n",
            "Processing ce_ce15.txt (353 of 472 files)\n",
            "Processing ca_ca20.txt (354 of 472 files)\n",
            "Processing cf_cf19.txt (355 of 472 files)\n",
            "Processing cg_cg49.txt (356 of 472 files)\n",
            "Processing cj_cj27.txt (357 of 472 files)\n",
            "Processing cg_cg33.txt (358 of 472 files)\n",
            "Processing ca_ca26.txt (359 of 472 files)\n",
            "Processing cj_cj20.txt (360 of 472 files)\n",
            "Processing cj_cj07.txt (361 of 472 files)\n",
            "Processing ca_ca41.txt (362 of 472 files)\n",
            "Processing ch_ch27.txt (363 of 472 files)\n",
            "Processing cd_cd05.txt (364 of 472 files)\n",
            "Processing cg_cg54.txt (365 of 472 files)\n",
            "Processing cg_cg04.txt (366 of 472 files)\n",
            "Processing cb_cb06.txt (367 of 472 files)\n",
            "Processing cm_cm01.txt (368 of 472 files)\n",
            "Processing cj_cj57.txt (369 of 472 files)\n",
            "Processing cf_cf10.txt (370 of 472 files)\n",
            "Processing cn_cn15.txt (371 of 472 files)\n",
            "Processing ch_ch14.txt (372 of 472 files)\n",
            "Processing cg_cg57.txt (373 of 472 files)\n",
            "Processing cf_cf43.txt (374 of 472 files)\n",
            "Processing cf_cf48.txt (375 of 472 files)\n",
            "Processing cj_cj73.txt (376 of 472 files)\n",
            "Processing cb_cb16.txt (377 of 472 files)\n",
            "Processing cc_cc04.txt (378 of 472 files)\n",
            "Processing cg_cg40.txt (379 of 472 files)\n",
            "Processing cc_cc06.txt (380 of 472 files)\n",
            "Processing ch_ch02.txt (381 of 472 files)\n",
            "Processing cf_cf02.txt (382 of 472 files)\n",
            "Processing ck_ck29.txt (383 of 472 files)\n",
            "Processing cf_cf42.txt (384 of 472 files)\n",
            "Processing ca_ca09.txt (385 of 472 files)\n",
            "Processing cj_cj54.txt (386 of 472 files)\n",
            "Processing cd_cd15.txt (387 of 472 files)\n",
            "Processing cl_cl04.txt (388 of 472 files)\n",
            "Processing ck_ck24.txt (389 of 472 files)\n",
            "Processing ca_ca16.txt (390 of 472 files)\n",
            "Processing cl_cl17.txt (391 of 472 files)\n",
            "Processing ce_ce32.txt (392 of 472 files)\n",
            "Processing cg_cg52.txt (393 of 472 files)\n",
            "Processing cp_cp08.txt (394 of 472 files)\n",
            "Processing ck_ck07.txt (395 of 472 files)\n",
            "Processing cl_cl18.txt (396 of 472 files)\n",
            "Processing cl_cl05.txt (397 of 472 files)\n",
            "Processing cn_cn06.txt (398 of 472 files)\n",
            "Processing cj_cj74.txt (399 of 472 files)\n",
            "Processing cj_cj52.txt (400 of 472 files)\n",
            "Processing cg_cg42.txt (401 of 472 files)\n",
            "Processing cn_cn01.txt (402 of 472 files)\n",
            "Processing cb_cb26.txt (403 of 472 files)\n",
            "Processing cg_cg28.txt (404 of 472 files)\n",
            "Processing ck_ck15.txt (405 of 472 files)\n",
            "Processing cg_cg17.txt (406 of 472 files)\n",
            "Processing cg_cg13.txt (407 of 472 files)\n",
            "Processing ca_ca21.txt (408 of 472 files)\n",
            "Processing cc_cc01.txt (409 of 472 files)\n",
            "Processing cl_cl19.txt (410 of 472 files)\n",
            "Processing ca_ca14.txt (411 of 472 files)\n",
            "Processing cj_cj30.txt (412 of 472 files)\n",
            "Processing cf_cf08.txt (413 of 472 files)\n",
            "Processing ce_ce21.txt (414 of 472 files)\n",
            "Processing cg_cg55.txt (415 of 472 files)\n",
            "Processing cj_cj17.txt (416 of 472 files)\n",
            "Processing cg_cg74.txt (417 of 472 files)\n",
            "Processing cn_cn17.txt (418 of 472 files)\n",
            "Processing ca_ca36.txt (419 of 472 files)\n",
            "Processing cl_cl21.txt (420 of 472 files)\n",
            "Processing cb_cb09.txt (421 of 472 files)\n",
            "Processing cf_cf32.txt (422 of 472 files)\n",
            "Processing cg_cg72.txt (423 of 472 files)\n",
            "Processing ca_ca43.txt (424 of 472 files)\n",
            "Processing cn_cn22.txt (425 of 472 files)\n",
            "Processing cj_cj37.txt (426 of 472 files)\n",
            "Processing cj_cj04.txt (427 of 472 files)\n",
            "Processing cf_cf04.txt (428 of 472 files)\n",
            "Processing ca_ca22.txt (429 of 472 files)\n",
            "Processing cn_cn18.txt (430 of 472 files)\n",
            "Processing cc_cc07.txt (431 of 472 files)\n",
            "Processing cg_cg36.txt (432 of 472 files)\n",
            "Processing cc_cc14.txt (433 of 472 files)\n",
            "Processing ca_ca08.txt (434 of 472 files)\n",
            "Processing ck_ck28.txt (435 of 472 files)\n",
            "Processing cg_cg43.txt (436 of 472 files)\n",
            "Processing cf_cf14.txt (437 of 472 files)\n",
            "Processing ce_ce06.txt (438 of 472 files)\n",
            "Processing ce_ce12.txt (439 of 472 files)\n",
            "Processing cb_cb12.txt (440 of 472 files)\n",
            "Processing cn_cn29.txt (441 of 472 files)\n",
            "Processing cj_cj79.txt (442 of 472 files)\n",
            "Processing ch_ch16.txt (443 of 472 files)\n",
            "Processing ck_ck01.txt (444 of 472 files)\n",
            "Processing cf_cf01.txt (445 of 472 files)\n",
            "Processing cj_cj59.txt (446 of 472 files)\n",
            "Processing cl_cl24.txt (447 of 472 files)\n",
            "Processing cg_cg03.txt (448 of 472 files)\n",
            "Processing ca_ca35.txt (449 of 472 files)\n",
            "Processing ch_ch12.txt (450 of 472 files)\n",
            "Processing cm_cm02.txt (451 of 472 files)\n",
            "Processing ce_ce29.txt (452 of 472 files)\n",
            "Processing cg_cg61.txt (453 of 472 files)\n",
            "Processing cf_cf22.txt (454 of 472 files)\n",
            "Processing ce_ce01.txt (455 of 472 files)\n",
            "Processing cb_cb20.txt (456 of 472 files)\n",
            "Processing ce_ce14.txt (457 of 472 files)\n",
            "Processing cd_cd03.txt (458 of 472 files)\n",
            "Processing cb_cb01.txt (459 of 472 files)\n",
            "Processing cf_cf41.txt (460 of 472 files)\n",
            "Processing ce_ce08.txt (461 of 472 files)\n",
            "Processing cg_cg23.txt (462 of 472 files)\n",
            "Processing cg_cg50.txt (463 of 472 files)\n",
            "Processing ce_ce16.txt (464 of 472 files)\n",
            "Processing cg_cg71.txt (465 of 472 files)\n",
            "Processing ca_ca06.txt (466 of 472 files)\n",
            "Processing cg_cg53.txt (467 of 472 files)\n",
            "Processing ce_ce35.txt (468 of 472 files)\n",
            "Processing ck_ck11.txt (469 of 472 files)\n",
            "Processing ce_ce03.txt (470 of 472 files)\n",
            "Processing cl_cl06.txt (471 of 472 files)\n",
            "Processing cd_cd04.txt (472 of 472 files)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ct.head(bg_dict[\"bi_freq\"], hits = 10)\n",
        "#other keys include \"dep_freq\", \"head_freq\", and \"range\"\n",
        "#also note that the key \"samples\" can be used to obtain a list of sample sentences\n",
        "#but, this is not compatible with the ct.head() function (see ct.dep_conc() instead)"
      ],
      "metadata": {
        "id": "nZVAjrjgKP6l",
        "outputId": "49dccab7-49fc-4bcc-fef0-8edb3436e030",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what_do\t223\n",
            "place_take\t82\n",
            "what_say\t66\n",
            "him_told\t58\n",
            "it_do\t52\n",
            "that_do\t47\n",
            "this_do\t43\n",
            "what_mean\t43\n",
            "time_have\t42\n",
            "effect_have\t41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Strength of association\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Various measures of strength of association can calculated between dependents and heads. The soa() function takes a dictionary generated by the dep_bigram() function and calculates the strength of association for each dependency bigram."
      ],
      "metadata": {
        "id": "ssf1gr1dGcmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soa_mi = ct.soa(bg_dict,stat = \"MI\")\n"
      ],
      "metadata": {
        "id": "8YpUhR2eGepx"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#other stat options include: \"T\", \"faith_dep\", \"faith_head\",\"dp_dep\", and \"dp_head\"\n",
        "ct.head(soa_mi, hits = 10)"
      ],
      "metadata": {
        "id": "y6aYAXOwKjS6",
        "outputId": "d02b04c2-e6c3-46c8-adca-d534533b0703",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class_judge\t10.911712979065362\n",
            "cigarette_smoke\t10.824250137815023\n",
            "nose_scratch\t10.712641631963534\n",
            "suicide_commit\t10.610543444344797\n",
            "nose_blow\t10.267856789290636\n",
            "imagination_capture\t10.07521171134824\n",
            "calendar_adjust\t9.812177305514448\n",
            "English_speak\t9.509614535494016\n",
            "resemblance_bear\t9.21127326092427\n",
            "contract_award\t9.156825476901894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Concordance lines for dependency bigrams\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "A number of excellent cross-platform GUI- based concordancers such as AntConc are freely available, and are likely the preferred method for most concordancing.\n",
        "\n",
        "However, it is difficult to get concordance lines for dependency bigrams without a more advanced program. The dep_conc() function takes the samples generated by the dep_bigram() function and creates a random sample of hits (50 hits by default) formatted as an html file.\n",
        "\n",
        "The following example will write an html file named \"dobj_results.html\" to your working directory."
      ],
      "metadata": {
        "id": "l-0gNsPjGg3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ct.dep_conc(bg_dict[\"samples\"],\"dobj_results\")"
      ],
      "metadata": {
        "id": "B5OauII5Gohb"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9WZRxTmVGq8T"
      }
    }
  ]
}